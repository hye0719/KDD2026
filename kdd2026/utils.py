"""
Utility Functions for Metalens Project
- Device detection (CUDA, MPS, CPU)
- Path management
- Config handling
"""

import os
import shutil
import torch
import yaml
from datetime import datetime


def get_device(device_config="auto"):
    """
    Device ìë™ ê°ì§€ ë° ì„¤ì •
    
    Args:
        device_config: "auto", "cuda", "mps", "cpu"
    
    Returns:
        torch.device
    """
    if device_config == "auto":
        if torch.cuda.is_available():
            device = torch.device("cuda")
            print(f"ğŸ”¥ Device: CUDA ({torch.cuda.get_device_name(0)})")
        elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
            device = torch.device("mps")
            print(f"ğŸ Device: MPS (Apple Silicon)")
        else:
            device = torch.device("cpu")
            print(f"ğŸ’» Device: CPU")
    elif device_config == "cuda":
        if torch.cuda.is_available():
            device = torch.device("cuda")
            print(f"ğŸ”¥ Device: CUDA ({torch.cuda.get_device_name(0)})")
        else:
            print("âš ï¸ CUDA not available, falling back to CPU")
            device = torch.device("cpu")
    elif device_config == "mps":
        if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
            device = torch.device("mps")
            print(f"ğŸ Device: MPS (Apple Silicon)")
        else:
            print("âš ï¸ MPS not available, falling back to CPU")
            device = torch.device("cpu")
    else:
        device = torch.device("cpu")
        print(f"ğŸ’» Device: CPU")
    
    return device


def create_experiment_dir(config, model_type, dim):
    """
    ì‹¤í—˜ ë””ë ‰í† ë¦¬ ìƒì„± (checkpoint, result)
    
    Args:
        config: ì„¤ì • ë”•ì…”ë„ˆë¦¬
        model_type: ëª¨ë¸ íƒ€ì…
        dim: ì°¨ì›
    
    Returns:
        checkpoint_dir, result_dir
    """
    output_cfg = config['output']
    
    # íƒ€ì„ìŠ¤íƒ¬í”„
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # ì‹¤í—˜ ì´ë¦„
    exp_name = f"{model_type}_{dim}_{timestamp}"
    
    # ë””ë ‰í† ë¦¬ ê²½ë¡œ
    checkpoint_dir = os.path.join(output_cfg['checkpoint_dir'], exp_name)
    result_dir = os.path.join(output_cfg['result_dir'], exp_name)
    
    # ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(checkpoint_dir, exist_ok=True)
    os.makedirs(result_dir, exist_ok=True)
    
    print(f"ğŸ“ Checkpoint dir: {checkpoint_dir}")
    print(f"ğŸ“ Result dir: {result_dir}")
    
    return checkpoint_dir, result_dir


def save_config(config, save_dir, filename="config.yaml"):
    """
    ì„¤ì • íŒŒì¼ì„ ì €ì¥ ë””ë ‰í† ë¦¬ì— ë³µì‚¬
    
    Args:
        config: ì„¤ì • ë”•ì…”ë„ˆë¦¬
        save_dir: ì €ì¥ ë””ë ‰í† ë¦¬
        filename: íŒŒì¼ëª…
    """
    save_path = os.path.join(save_dir, filename)
    with open(save_path, 'w') as f:
        yaml.dump(config, f, default_flow_style=False, allow_unicode=True)
    print(f"ğŸ“ Config saved to {save_path}")


def load_config(config_path):
    """
    ì„¤ì • íŒŒì¼ ë¡œë“œ
    
    Args:
        config_path: ì„¤ì • íŒŒì¼ ê²½ë¡œ
    
    Returns:
        config dict
    """
    with open(config_path, 'r') as f:
        config = yaml.safe_load(f)
    return config


def set_seed(seed):
    """
    ëœë¤ ì‹œë“œ ì„¤ì •
    
    Args:
        seed: ì‹œë“œ ê°’
    """
    import random
    import numpy as np
    
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    
    if torch.cuda.is_available():
        torch.cuda.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)
    
    # MPSì˜ ê²½ìš° ë³„ë„ ì‹œë“œ ì„¤ì • ì—†ìŒ
    
    print(f"ğŸ² Random seed set to {seed}")


def count_parameters(model):
    """
    ëª¨ë¸ íŒŒë¼ë¯¸í„° ìˆ˜ ê³„ì‚°
    
    Args:
        model: PyTorch ëª¨ë¸
    
    Returns:
        ì´ íŒŒë¼ë¯¸í„° ìˆ˜, í•™ìŠµ ê°€ëŠ¥ íŒŒë¼ë¯¸í„° ìˆ˜
    """
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    
    return total_params, trainable_params


def print_model_info(model, model_type, dim):
    """
    ëª¨ë¸ ì •ë³´ ì¶œë ¥
    
    Args:
        model: PyTorch ëª¨ë¸
        model_type: ëª¨ë¸ íƒ€ì…
        dim: ì°¨ì›
    """
    total, trainable = count_parameters(model)
    
    print(f"\n{'='*50}")
    print(f"ğŸ“¦ Model: {model_type.upper()} ({dim.upper()})")
    print(f"   Total parameters: {total:,}")
    print(f"   Trainable parameters: {trainable:,}")
    print(f"{'='*50}\n")
